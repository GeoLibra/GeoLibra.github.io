<!DOCTYPE html>
<html lang="">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="图像识别与卷积神经网络"/>




  <meta name="keywords" content="Tensorflow, 磊哥的小书桌" />










  <link rel="alternate" href="/default" title="磊哥的小书桌">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.1" />



<link rel="canonical" href="https://geolibra.github.io/2018/10/29/图像识别与卷积神经网络/"/>



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css" />



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.1" />



  <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?97659041a2db55d3eb7266f53be7c071";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>





  <script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
  <script id="leancloud">
    AV.init({
      appId: "ro3TOe5F5DDemxHnSoYVCHli-gzGzoHsz",
      appKey: "IHyD5EfrggPl57FnwtBEeH0W"
    });
  </script>




<script>
  window.config = {"title":"磊哥的小书桌","subtitle":null,"description":null,"author":"hgis","language":null,"timezone":null,"url":"https://geolibra.github.io","root":"/","permalink":":year/:month/:day/:title/","permalink_defaults":null,"source_dir":"source","public_dir":"public","tag_dir":"tags","archive_dir":"archives","category_dir":"categories","code_dir":"downloads/code","i18n_dir":":lang","skip_render":null,"new_post_name":":title.md","default_layout":"post","titlecase":false,"external_link":true,"filename_case":0,"render_drafts":false,"post_asset_folder":true,"relative_link":false,"future":true,"highlight":{"enable":true,"auto_detect":false,"line_number":true,"tab_replace":null,"first_line_number":"always1"},"default_category":"uncategorized","category_map":null,"tag_map":null,"date_format":"YYYY-MM-DD","time_format":"HH:mm:ss","per_page":10,"pagination_dir":"page","theme":"even","deploy":{"type":"git","repository":"git@github.com:GeoLibra/GeoLibra.github.io.git","branch":"master"},"ignore":[],"keywords":null,"email":"674530915@qq.com","index_generator":{"per_page":10,"order_by":"-date","path":""},"tag_cloud":{"textFont":"Trebuchet MS, Helvetica","textColour":"\\#eea849","textHeight":25,"outlineColour":"\\#E2E1D1"},"archive_generator":{"per_page":10,"yearly":true,"monthly":true,"daily":false},"category_generator":{"per_page":10},"marked":{"gfm":true,"pedantic":false,"sanitize":false,"tables":true,"breaks":true,"smartLists":true,"smartypants":true,"modifyAnchors":"","autolink":true},"tag_generator":{"per_page":10},"server":{"port":4000,"log":false,"compress":false,"header":true},"since":2018,"favicon":"/favicon.ico","rss":"default","menu":{"Home":"/","Archives":"/archives/","Tags":"/tags","Categories":"/categories","About":"/about"},"color":"default","mode":"default","toc":true,"fancybox":true,"pjax":true,"copyright":{"enable":true,"license":"<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\" target=\"_blank\">知识共享署名-非商业性使用 4.0 国际许可协议</a>"},"reward":{"enable":false,"qrCode":{"wechat":null,"alipay":null}},"social":{"email":"674530915@qq.com","stack-overflow":null,"twitter":null,"facebook":null,"linkedin":null,"google":null,"github":"https://github.com/GeoLibra","weibo":null,"zhihu":null,"douban":null,"pocket":null,"tumblr":null,"instagram":null},"leancloud":{"app_id":"ro3TOe5F5DDemxHnSoYVCHli-gzGzoHsz","app_key":"IHyD5EfrggPl57FnwtBEeH0W"},"baidu_analytics":"97659041a2db55d3eb7266f53be7c071","baidu_verification":null,"google_analytics":null,"google_verification":null,"disqus_shortname":null,"changyan":{"appid":null,"appkey":null},"livere_datauid":null,"counter":true,"version":"2.10.1"};
</script>

    <title> 图像识别与卷积神经网络 - 磊哥的小书桌 </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">磊哥的小书桌</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            分类
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">磊哥的小书桌</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          图像识别与卷积神经网络
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-10-29
        </span>
        
          <span class="post-category">
            
              <a href="/categories/深度学习/">深度学习</a>
            
          </span>
        
        
        <span class="post-visits"
             data-url="/2018/10/29/图像识别与卷积神经网络/"
             data-title="图像识别与卷积神经网络">
          阅读次数 0
        </span>
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积神经网络简介"><span class="toc-text">卷积神经网络简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#全连接神经网络"><span class="toc-text">全连接神经网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#卷积"><span class="toc-text">卷积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#全零填充"><span class="toc-text">全零填充</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#池化Pooling"><span class="toc-text">池化Pooling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#舍弃Dropout"><span class="toc-text">舍弃Dropout</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#卷积NN"><span class="toc-text">卷积NN</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Letnet-5"><span class="toc-text">Letnet-5</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Letnet-5模型结构"><span class="toc-text">Letnet-5模型结构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#第一层-卷积层"><span class="toc-text">第一层,卷积层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#第二层-池化层"><span class="toc-text">第二层,池化层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#第三层-卷积层"><span class="toc-text">第三层,卷积层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#第四层-池化层"><span class="toc-text">第四层,池化层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#第五层-全连接层"><span class="toc-text">第五层,全连接层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#第六层-全连接层"><span class="toc-text">第六层,全连接层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#第七层-全连接层"><span class="toc-text">第七层,全连接层</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Inception-v3模型"><span class="toc-text">Inception-v3模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积神经网络的迁移学习"><span class="toc-text">卷积神经网络的迁移学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#反卷积神经网络"><span class="toc-text">反卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#反卷积原理"><span class="toc-text">反卷积原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#反池化原理"><span class="toc-text">反池化原理</span></a></li></ol></li></ol>
    </div>
  </div>



    <div class="post-content">
      
        <h2 id="卷积神经网络简介"><a href="#卷积神经网络简介" class="headerlink" title="卷积神经网络简介"></a>卷积神经网络简介</h2><h3 id="全连接神经网络"><a href="#全连接神经网络" class="headerlink" title="全连接神经网络"></a>全连接神经网络</h3><p>每个神经元与前后相邻层的每一个神经元都有连接关系，输入是特征。输出是预测的结果。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">参数个数:∑(前层X后层+后层)</span><br></pre></td></tr></table></figure></p>
<img src="/2018/10/29/图像识别与卷积神经网络/nn.jpg" title="全连接神经网络">
<a id="more"></a>
<p>一张分辨率仅仅是28x28 的黑白图像，就有近40 万个待优化的参数。现实生活中高分辨率的彩色图像，像素点更多，且为红绿蓝三通道信息。待优化的参数过多，容易导致模型过拟合。为避免这种现象，实际应用中一般不会将原始图片直接喂入全连接网络。</p>
<p>在实际应用中，会先对原始图像进行特征提取，把提取到的特征喂给全连接网络，再让全连接网络计算出分类评估值。<br><img src="/2018/10/29/图像识别与卷积神经网络/nn2.jpg" title="一般做法"></p>
<p>例：先将此图进行多次特征提取，再把提取后的计算机可读特征喂给全连接网络 。</p>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>卷积是一种有效提取图片特征的方法。一般用一个正方形卷积核，遍历图片上的每一个像素点。图片与卷积核重合区域内相对应的每一个像素值乘卷积核内相对应点的权重，然后求和，再加上偏置后，最后得到输出图片中的一个像素值。<br><img src="/2018/10/29/图像识别与卷积神经网络/cnn.jpg" title="卷积"></p>
<p>例：上面是 5x5x1 的灰度图片，1 表示单通道，5x5 表示分辨率，共有 5 行 5列个灰度值。若用一个 3x3x1 的卷积核对此 5x5x1 的灰度图片进行卷积，偏置项b=1，则求卷积的计算是：(-1)x1+0x0+1x2+(-1)x5+0x4+1x2+(-1)x3+0x4+1x5+1=1（注意不要忘记加偏置 1）。<br>输出图片边长=（输入图片边长–卷积核长+1）/步长，此图为：（5 – 3 + 1）/ 1 = 3，输出图片是 3x3 的分辨率，用了 1 个卷积核，输出深度是 1，最后输出的是3x3x1 的图片。 </p>
<h3 id="全零填充"><a href="#全零填充" class="headerlink" title="全零填充"></a>全零填充</h3><p>有时会在输入图片周围进行全零填充，这样可以保证输出图片的尺寸和输入图片一致。<br><img src="/2018/10/29/图像识别与卷积神经网络/padding.jpg" title="全零填充"></p>
<p>例：在前面 5x5x1 的图片周围进行全零填充，可使输出图片仍保持 5x5x1 的维度。这个全零填充的过程叫做 padding。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输出数据体的尺寸=(W−F+2P)/S+1</span><br><span class="line">W：输入数据体尺寸，F：卷积层中神经元感知域，S：步长，P：零填充的数量。</span><br></pre></td></tr></table></figure></p>
<p>例：输入是 7×7，滤波器是 3×3，步长为 1，填充为 0，那么就能得到一个 5×5的输出。如果步长为 2，输出就是 3×3。 如果输入量是 32x32x3，核是 5x5x3，不用全零填充，输出是（32-5+1）/1=28，如果要让输出量保持在 32x32x3，可以对该层加一个大小为 2 的零填充。可以根据需求计算出需要填充几层零。32=（32-5+2P）/1 +1，计算出 P=2，即需填充 2层零。<br><img src="/2018/10/29/图像识别与卷积神经网络/padding2.jpg" title="全零填充举例"></p>
<p>使用padding和不使用padding的输出维度<br><img src="/2018/10/29/图像识别与卷积神经网络/padding3.jpg" title="输出维度"></p>
<p>上一行公式是使用 padding 的输出图片边长，下一行公式是不使用 padding的输出图片边长。公式如果不能整除，需要向上取整数。如果用全零填充，也就是padding=SAME。如果不用全零填充，也就是 padding=VALID。</p>
<p>Tenorflow给出的计算卷积核的函数<br><img src="/2018/10/29/图像识别与卷积神经网络/conv2d.jpg" title="输出维度"></p>
<p>函數中要给出四个信息：对输入图片的描述、对卷积核的描述、对卷积核滑动步长的描述以及是否使用padding。</p>
<p>1）对输入图片的描述：用batch给出一次喂入多少张图片，每张图片分辨率大小，比如5x5，以及这些图片包含几个通道的信息，如果是灰度图则是单通道，参数为1，如果是彩色图像则为红绿蓝三通道，则为3。</p>
<p>2）对卷积核的描述：要给出卷积核的行分辨率和列分辨率、通道数以及用了几个卷积核。比如上图描述，辨识卷积核行列分辨率为3行和3列，而且是1通道的，一共有16个这样的卷积核，卷积核的通道数是由输入图片的通道数决定的，卷积核的通道数等于输入图片的通道数，所以卷积核的通道数也是1，一共有16个这样的卷积核，说明卷积操作后输出图片的深度是16，也就是输出为16个通道。</p>
<p>3）对卷积核滑动步长的描述：上图第二个参数表示横向滑动步长，第三个参数表示纵向滑动步长，第一个和最后一个都要求是1.</p>
<p>4）是否使用padding</p>
<p>多数情况下，输入图片是RGB三个颜色组成的彩色图，输入图片包含了红绿蓝三层数据，卷积核的深度应该等于输入图片的通道数，所以使用3x3x3的卷积核，最后一个3表示匹配输入图像的3个通道，这样的卷积核有3层，每层会随机生成9个待优化参数，一共27个待优化参数w和一个偏置b。<br><img src="/2018/10/29/图像识别与卷积神经网络/rgb.jpg" title="彩色图像的卷积"></p>
<p>对于彩色图，按层分解开，可以直观表示为上面这张图，红绿蓝三个颜色分量。卷积核为了匹配三个颜色，把三层的卷积核套在三层的彩色图片上，重合的27个像素进行对应点的乘加运算，最后的结果再加上偏置项b，求得输出图片中的一个值。<br>这个5x5x3的输入图片加了全零填充，使用3x3x卷积核，所有27个点与对应的待优化参数相乘，乘机求和再加上偏置b得到输出图片中的一个值6。<br>针对上面这幅彩色图，用conv2d函数实现可以表示为：<br>一次输入batch张图片，输入图片的分辨率是5x5，3通道，卷积核是3x3x3，一共有16个卷积核，这样输出的深度就是16，核滑动步长是1，纵向步长也是1，padding选择same，保证输出5x5分辨率。由于一共用了16个卷积核，所以输出图片是5x5x16。</p>
<h3 id="池化Pooling"><a href="#池化Pooling" class="headerlink" title="池化Pooling"></a>池化Pooling</h3><p>池化层也称子采样层或下采样层。通过对输入数据的各个维度进行空间采样，可以进一步降低数据规模，并且对输入数据具有局部线性转换不变性，增强网络的泛化处理能力。<br><img src="/2018/10/29/图像识别与卷积神经网络/pooling.jpg" title="池化公式"></p>
<p>1）对输入的描述：给出一次输入batch张图片、行列分辨率、输入通道的个数</p>
<p>2）对池化核的描述：只描述行列分辨率，第一个和最后一个参数固定是1。</p>
<p>3）对池化核滑动步长的描述：只描述横向滑动步长和纵向滑动步长，第一个和最后一个参数固定是1。</p>
<p>4）是否使用padding：SAME零填充或VALID不使用0填充。<br>池化与卷积很像，只是算法不同：  </p>
<ul>
<li>卷积是将对应像素上的点相乘，然后相加</li>
<li>池化只关心滤波器的尺寸，不考虑内部的值。算法是，滤波器映射区域内的像素点去平均值或最大值。<br>均值池化：得到的特征对背景信息更敏感。<br>最大池化：对纹理特征信息更敏感。</li>
</ul>
<h3 id="舍弃Dropout"><a href="#舍弃Dropout" class="headerlink" title="舍弃Dropout"></a>舍弃Dropout</h3><img src="/2018/10/29/图像识别与卷积神经网络/dropout.jpg" title="舍弃">
<p>在神经网络驯良过程中，为了减少过多参数常使用dropout的方法，将一部分神经元按照一定的概率从神经网络中舍弃。这种舍弃是临时性的，仅在训练时舍弃一些神经元；在使用神经网络时，会 把所有的神经元恢复到神经网络中。比如上面这张图，在训练时一些神经元不参与神经网络计算了，Drop可以有效减少过拟合。<br>用tf.nn.dropout函数，第一个参数链接上一层的输出，第二个参数给出神经元舍弃的概率。在实际应用中，常常在前向传播构建神经网络时使用dropout来减小过拟合加快模型的训练速度。<br>dropout一般会放到全连接网络中。如果在训练参数的过程中，输出=tf.nn.dropout(上层输出,暂时舍弃神经元的概率)，这样就有指定概率的神经元被随机置0，置0的神经元不参加当前轮的参数优化。</p>
<h3 id="卷积NN"><a href="#卷积NN" class="headerlink" title="卷积NN"></a>卷积NN</h3><p>借助卷积核提取特征后，送入全连接网络。卷积神经网络可以认为由两部分组成，一部分是对输入图片进行特征提取，另一部分就是全连接网络，只不过喂入全连接网络的不再是原始图片，而是经过若干次卷积、激活和池化后的特征信息。</p>
<h2 id="Letnet-5"><a href="#Letnet-5" class="headerlink" title="Letnet-5"></a>Letnet-5</h2><h3 id="Letnet-5模型结构"><a href="#Letnet-5模型结构" class="headerlink" title="Letnet-5模型结构"></a>Letnet-5模型结构</h3><h4 id="第一层-卷积层"><a href="#第一层-卷积层" class="headerlink" title="第一层,卷积层"></a>第一层,卷积层</h4><p>这一层的输入就是原始的图像像素，LetNet-5模型接受的输入层大小为32x32x1。第一个卷积层过滤器尺寸为5x5，深度为6，不使用全0填充，步长为1。因为没有使用全0填充，所以这一层的输出尺寸为32-5+1=28，深度为6.这个卷积层共有5x5x1x6+6=156个参数，其中6个为偏置项参数。因为下一层的节点矩阵有28x28x6=4704个节点，每个节点和5x5=25个当前层节点相连，所以本层卷积层共有4704x(25+1)=122304个连接。</p>
<h4 id="第二层-池化层"><a href="#第二层-池化层" class="headerlink" title="第二层,池化层"></a>第二层,池化层</h4><p>这一层的输入为上一层的输出，是一个28x28x6的节点矩阵。本层采用过滤器大小为2x2，长和宽的步长均为2，所以本层的输出矩阵大小为14x14x6。</p>
<h4 id="第三层-卷积层"><a href="#第三层-卷积层" class="headerlink" title="第三层,卷积层"></a>第三层,卷积层</h4><p>本层输入矩阵大小为14x14x6，使用的过滤器大小为5x5，深度为16.本层不使用全0填充，步长为1.本层的输出矩阵大小为10x10x16.按照标准的卷积层，本层应该有5x5x6x16+16=2416个参数，10x10x15x(25+1)=41600个连接。</p>
<h4 id="第四层-池化层"><a href="#第四层-池化层" class="headerlink" title="第四层,池化层"></a>第四层,池化层</h4><p>本层的输入矩阵大小为10x10x16，采用的过滤器大小为2x2，步长为2.本层的输出矩阵大小为5x5x16。</p>
<h4 id="第五层-全连接层"><a href="#第五层-全连接层" class="headerlink" title="第五层,全连接层"></a>第五层,全连接层</h4><p>本层的输入矩阵5x5x16，在LetNet-5模型论文中将这一层称为卷积层，但是因为过滤器的大小就是5x5，所以和全连接层没有区别。本层的输出节点为120，总共有5x5x16x120+120=48120个参数。</p>
<h4 id="第六层-全连接层"><a href="#第六层-全连接层" class="headerlink" title="第六层,全连接层"></a>第六层,全连接层</h4><p>本层的输入节点个数为120个，输出节点个数为84个，总共参数为120x84+84=10164个。</p>
<h4 id="第七层-全连接层"><a href="#第七层-全连接层" class="headerlink" title="第七层,全连接层"></a>第七层,全连接层</h4><p>本层的输入节点个数为84个，输出节点为10个，总共参数为120x84+84=10164个。</p>
<p>Letnet神经网络的输入是32<em>32</em>1，经过5<em>5</em>1的卷积核，卷积核的个数为6个，采用非全零填充方式，步长为1，根据非全零填充计算公司：输出尺寸=(输入尺寸-卷积核尺寸+1)/步长=(32-5+1)/1=28.故经过卷积后输出为28<em>28</em>6.<br>经过池化第一层池化层，池化大小为2<em>2，全零填充，步长为2，由全零填充计算公式：输出尺寸=输入尺寸/步长=28/2=14.池化层不改变深度，深度仍为6.用同样的计算方法，得到第二层池化后的输出为5</em>5*16.将第二池化层后的输出拉直送入全连接层。<br></p>
<p>对letnet神经网络进行微调，使其适应Mnist数据集：<br>由于Mnist数据集中图片大小为28<em>28</em>1的灰度图片，而Letnet神经网络的输入为32<em>32</em>1，故要对Letnet神经网络进行微调。  </p>
<ol>
<li>输入为28<em>28</em>1的图片大小，为单通道输入；</li>
<li>进行卷积，卷积核大小为5<em>5</em>1，个数为32，步长为1，全零填充模式；</li>
<li>将卷积结果通过非线性激活函数；</li>
<li>进行池化，池化大小为2*2，步长为2，全零填充模式；</li>
<li>进行卷积，卷积核大小为5<em>5</em>32，个数为64，步长为1，全零填充模式；</li>
<li>将卷积结果通过非线性激活函数；</li>
<li>进行池化，池化大小为2*2，步长为2，全零填充模式；</li>
<li><p>全连接层，进行10分类。</p>
<img src="/2018/10/29/图像识别与卷积神经网络/letnet_mnist.png" title="letnet神经网络微调">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 定义神经网络结构的相关参数</span></span><br><span class="line">INPUT_NODE = <span class="number">784</span></span><br><span class="line">OUTPUT_NODE = <span class="number">10</span></span><br><span class="line">LAYER1_NODE = <span class="number">500</span></span><br><span class="line"></span><br><span class="line">IMAGE_SIZE = <span class="number">28</span></span><br><span class="line">NUM_CHANNELS = <span class="number">1</span></span><br><span class="line">NUM_LABELS = <span class="number">10</span></span><br><span class="line"><span class="comment"># 第一层的尺寸和深度</span></span><br><span class="line">CONV1_DEEP = <span class="number">32</span></span><br><span class="line">CONV1_SIZE = <span class="number">5</span></span><br><span class="line"><span class="comment"># 第二层卷基层的尺度和深度</span></span><br><span class="line">CONV2_DEEP = <span class="number">64</span></span><br><span class="line">CONV2_SIZE = <span class="number">5</span></span><br><span class="line"><span class="comment"># 全连接层的节点个数</span></span><br><span class="line">FC_SIZE = <span class="number">512</span></span><br><span class="line">OUTPUT_NODE = <span class="number">10</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weight</span><span class="params">(shape, regularizer)</span>:</span></span><br><span class="line">    w = tf.Variable(tf.truncated_normal(shape, stddev=<span class="number">0.1</span>))</span><br><span class="line">    <span class="keyword">if</span> regularizer != <span class="keyword">None</span>:</span><br><span class="line">        tf.add_to_collection(</span><br><span class="line">            name=<span class="string">'losses'</span>,</span><br><span class="line">            value=tf.contrib.layers.l2_regularizer(regularizer)(w))</span><br><span class="line">    <span class="keyword">return</span> w</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_bias</span><span class="params">(shape)</span>:</span></span><br><span class="line">    b = tf.Variable(tf.zeros(shape))</span><br><span class="line">    <span class="keyword">return</span> b</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, w)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(</span><br><span class="line">        input=x, filter=w, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SNAME'</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(</span><br><span class="line">        inoput=x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SNAME'</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(x, train, regularizer)</span>:</span></span><br><span class="line">    conv1_w = get_weight([CONV1_SIZE, CONV1_SIZE, NUM_CHANNELS, CONV1_DEEP],</span><br><span class="line">                         regularizer)</span><br><span class="line">    conv1_b = get_bias([CONV1_DEEP])</span><br><span class="line">    conv1 = conv2d(x, conv1_w)</span><br><span class="line">    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_b))</span><br><span class="line">    pool1 = max_pool_2x2(relu1)</span><br><span class="line"></span><br><span class="line">    conv2_w = get_weight([CONV2_SIZE, CONV2_SIZE, CONV1_DEEP, CONV1_DEEP],</span><br><span class="line">                         regularizer)</span><br><span class="line">    conv2_b = get_bias([CONV2_DEEP])</span><br><span class="line">    conv2 = conv2d(pool1, conv2_w)</span><br><span class="line">    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_b))</span><br><span class="line">    pool2 = max_pool_2x2(relu2)</span><br><span class="line"></span><br><span class="line">    pool_shape = pool2.get_shape().as_list()</span><br><span class="line">    nodes = pool_shape[<span class="number">1</span>] * pool_shape[<span class="number">2</span>] * pool_shape[<span class="number">3</span>]</span><br><span class="line">    reshaped = tf.reshape(pool2, [pool_shape[<span class="number">0</span>], nodes])</span><br><span class="line"></span><br><span class="line">    fc1_w = get_weight([nodes, FC_SIZE], regularizer)</span><br><span class="line">    fc1_b = get_bias([FC_SIZE])</span><br><span class="line">    fc1 = tf.nn.relu(tf.matmul(reshaped, fc1_w) + fc1_b)</span><br><span class="line">    <span class="keyword">if</span> train:</span><br><span class="line">        fc1 = tf.nn.dropout(fc1, <span class="number">0.5</span>)</span><br><span class="line">    fc2_w = get_weight([FC_SIZE, OUTPUT_NODE], regularizer)</span><br><span class="line">    fc2_b = get_bias([OUTPUT_NODE])</span><br><span class="line">    y = tf.matmul(fc1, fc2_w) + fc2_b</span><br><span class="line">    <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
</li>
<li><p>定义前向传播过程中常用到的参数。<br>图片大小即每张图片分辨率为28*28，故IMAGE_SIZE取值为28；Mnist数据集为灰度图，故输入图片的通道数NUM_CHANNELS取值为1；第一层卷积核大小为5，卷积核个数为32，故CONV1_SIZE取值为5，CONV1_DEEP取值为32；第二层卷积核大小为5，卷积核个数为64，故CONV2_SIZE取值为5，CONV2_DEEP为64.全连接层第一层参数为512个神经元，全连接层第二层为10个神经元，故FC_SIZE取值为512，OUTPUT_NODE取值为10，实现10分类输出。  </p>
</li>
<li>吧把前向传播过程中，常用到的方法定义为函数，方便调用。<br>定义常用的4个函数：权重w生成函数、偏置b生成函数、卷积层计算函数、最大池化层计算函数。  </li>
<li><p>定义前向传播过程  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现第一层卷积 </span></span><br><span class="line"><span class="comment"># 根据先抢定义的参数大小,初始化第一层卷积核和偏置项</span></span><br><span class="line">conv1_w = get_weight([CONV1_SIZE, CONV1_SIZE, NUM_CHANNELS, CONV1_DEEP],</span><br><span class="line">                         regularizer)</span><br><span class="line">conv1_b = get_bias([CONV1_DEEP])</span><br><span class="line"><span class="comment"># 实现卷积运算,输入参数为x和第一层卷积核参数</span></span><br><span class="line">conv1 = conv2d(x, conv1_w)</span><br><span class="line"><span class="comment"># 第一层卷积的输出作为非线性激活函数的输入值,首先通过tf.nn.bias_add对卷积后的输出添加偏置项,</span></span><br><span class="line">并过tf.nn.relu完成非线性激活</span><br><span class="line">relu1=tf.nn.telu(tf.nn.bias_add(conv1,conv1_b))</span><br><span class="line"><span class="comment"># 根据先前定义的池化函数,将第一层激活后的输出值进行最大池化</span></span><br><span class="line">pool=max_pool_2x2(relu1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现第二层卷积  </span></span><br><span class="line"><span class="comment"># 初始化第二层卷积层的变量和偏置项,该层每个卷积核的通道数要与上一层卷积核的个数一致</span></span><br><span class="line">conv2_w=get_weight([CONV2_SIZE,CONV2_SIZE,CONV1_DEEP,CONV2_DEEP],regularizer)</span><br><span class="line">conv2_b=get_bias([CONV2_DEEP])</span><br><span class="line"><span class="comment"># 实现卷积运算,输入参数为上一层的输出pool1和第二层卷积核参数</span></span><br><span class="line">conv_2=conv2d(pool1,conv2_w)</span><br><span class="line"><span class="comment"># 实现第二层的非线性激活函数</span></span><br><span class="line">relu2=tf.nn.relu(tf.nn.boas_add(conv2,conv2_b))</span><br><span class="line"><span class="comment"># 根据提前定义的池化函数,将第二层激活后的输出值进行最大池化</span></span><br><span class="line">pool2=max_pool_2x2(relu2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将第二层的池化层输出pool2矩阵转化为全连接层的输入格式即向量形式</span></span><br><span class="line"><span class="comment"># 根据get_shape函数得到pool2输出矩阵的维度,并存入list.其中,pool_shape[0]为一个batch值</span></span><br><span class="line">pool_shape=pool2.get_shape().as_list()</span><br><span class="line"><span class="comment"># 从list中依次取出矩阵的长宽及深度,并求三者的乘积,得到矩阵被拉长后的长度</span></span><br><span class="line">nodes=pool_shape[<span class="number">1</span>] * pool_shape[<span class="number">2</span>] * pool_shape[<span class="number">3</span>]</span><br><span class="line"><span class="comment"># 将pool2转换为一个batch的向量再传入后续的全连接</span></span><br><span class="line">reshaped=tf.reshape(pool2,[pool_shape[<span class="number">0</span>],nodes)</span><br><span class="line"><span class="comment"># get_shape函数用于获取一个张量的维度,并且输出张量每个维度上面的值</span></span><br><span class="line"><span class="comment"># A=tf.random_normal(shape=[3,4]) # A.get_shape()  (3,4)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现第三层全连接层</span></span><br><span class="line"><span class="comment"># 初始化全连接层权重,并加入正则化</span></span><br><span class="line">fc1_w=get_weight([nodes,FC_SIZE],regularizer)</span><br><span class="line"><span class="comment"># 初始化全连接层的偏置项</span></span><br><span class="line">fc1_b=get_bias([FC_SIZE])</span><br><span class="line"><span class="comment"># 如果是训练阶段,则对该层输出使用dropout,也就是随机将该层输出中的一半神经元置为无效,</span></span><br><span class="line"><span class="comment">#是为了避免过拟合而设置的,一半只在全连接层中使用</span></span><br><span class="line">fc1=tf.nn.relu(tf.matmul(reshaped,fc1_w)+fc1_b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现第四层全连接层的前向传播过程:</span></span><br><span class="line"><span class="comment"># 初始化全连接层对应的变量</span></span><br><span class="line">fc2_w=get_weight([FC_SIZE,OUTPUT_NODE],regularizer)</span><br><span class="line">fc2_b=get_bias([OUTPUT_NODE])</span><br><span class="line"><span class="comment"># 将转换后的reshaped向量与权重fc2_w做矩阵乘法运算,然后再加上偏置</span></span><br><span class="line">y=tf.matmul(fc1,fc2_w)+fc2_b</span><br><span class="line"><span class="comment"># 返回输出值,完成整个前向传播过程</span></span><br><span class="line"><span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
</li>
<li><p>反向传播过程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.定义训练过程中的超参数</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">规定一个batch的数量为100,故BATCH_SIZE取值为100;设定初始学习率为0.005,</span></span><br><span class="line"><span class="string">学习衰减率为0.99;最大迭代次数为50000,故STEPS取值为50000;滑动平均衰减率设置为</span></span><br><span class="line"><span class="string">0.99,并规定模型保存的路径以及保存的模型名称</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># 2.完成反向传播过程</span></span><br><span class="line"><span class="comment"># 1)x,y_</span></span><br><span class="line">x=tf.placeholder(tf.float32,shape=[</span><br><span class="line">    BATCH_SIZE,</span><br><span class="line">    forward.IMAGE_SIZE,</span><br><span class="line">    forward.IMAGE_SIZE,</span><br><span class="line">    forward.NUM_CHANNELS</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line">y_=tf.placeholder(tf.float32,[<span class="keyword">None</span>,forward.OUTPUT_NODE])</span><br><span class="line"><span class="comment"># 调用前向传播过程</span></span><br><span class="line"><span class="comment"># 调用前向传播网络得到维度为10的tensor</span></span><br><span class="line">y=forward.forward(x,<span class="keyword">True</span>,REGULARIZER)</span><br><span class="line"><span class="comment"># 2)求含有正则化的损失值</span></span><br><span class="line"><span class="comment"># 声明一个全局计数器,并输出化为0</span></span><br><span class="line">global_step=tf.Variable(<span class="number">0</span>,trainable=<span class="keyword">False</span>)</span><br><span class="line"><span class="comment"># 对网络最后一层的输出做softmax,求取输出属于某一类的概率,结果为num_classes大小的向量,</span></span><br><span class="line"><span class="comment"># 再将此向量和实际标签值做交叉熵,返回一个向量值</span></span><br><span class="line">ce=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 通过reduce_mean函数对得到的向量求平均值得到loss</span></span><br><span class="line">cem=tf.reduce_mean(ce)</span><br><span class="line"><span class="comment"># 添加正则化中的losses值到loss中</span></span><br><span class="line">loss=cem+tf.add_n(tf.get_collection(<span class="string">'losses'</span>))</span><br><span class="line"><span class="comment"># 4)实现指数衰减学习率</span></span><br><span class="line">learning_rate=tf.train.exponential_decay(</span><br><span class="line">    LEARNING_RATE_BASE,</span><br><span class="line">    global_step,</span><br><span class="line">    mnist.train.num_examples/BATCH_SIZE,</span><br><span class="line">    LEARNING_RATE_DECAY,</span><br><span class="line">    staircase=<span class="keyword">True</span></span><br><span class="line">    )</span><br><span class="line"><span class="comment"># 次函数的参数learning_rate为传入的学习率,构造一个实现梯度下降算法的优化器,再通过使用minimize更新存储</span></span><br><span class="line">要训练的变量的列表来减小loss</span><br><span class="line">train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)</span><br><span class="line"><span class="comment"># 5)实现滑动平均模型</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">ExponentialMovingAverage函数采用滑动平均的方法更新参数,次函数的参数MONING_AVERAGE_DECAY表示衰减率,</span></span><br><span class="line"><span class="string">用于控制模型的更新速度;次函数维护一个影子变量,影子变量初始值作为变量初始值.</span></span><br><span class="line"><span class="string">影子变量值的更新方式如下:</span></span><br><span class="line"><span class="string">shadow_variable=decay * shadow_variable + (1-decay) * variable</span></span><br><span class="line"><span class="string">shadow_variable是影子变量,variable表示待更新的变量,decay为衰减率.</span></span><br><span class="line"><span class="string">decay一般设为接近于1的数,decay越大模型越稳定</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">ema=tf.train.ExponentialMovingAverage(MONING_AVERAGE_DECAY,global_step)</span><br><span class="line">ema_op=ema.apply(tf.trainable_variables())</span><br><span class="line"><span class="comment"># 6)将train_step和ema_op两个训练操作绑定到train_op</span></span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies([train_step,ema_op]):</span><br><span class="line">    train_op=tf.no_op(name=<span class="string">'train'</span>)</span><br><span class="line"><span class="comment"># 7)实例化一个保存和恢复变量的saver,并创建一个会话</span></span><br><span class="line">saver=tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op=tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    <span class="comment"># 创建一个会话,并通过python中的上下文管理器来管理这个会话,初始化计算图中的变量,并用sess.run实现初始化</span></span><br><span class="line">    ckpt=tf.train.get_checkpoint_state(MODEL_SAVE_PATH)</span><br><span class="line">    <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">        saver.restore(sess,ckpt.model_checkpoint_path)</span><br><span class="line">    <span class="comment"># 通过checkpoing文件定位到最新保存的模型,若文件存在,则加载最新的模型</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line">    <span class="comment"># 读取一个batch数据,将输入数据xs转成与网络输入相同形状的矩阵</span></span><br><span class="line">        xs,ys=mnist.train.next_batch(BATCH_SIZE)</span><br><span class="line">        reshaped_xs=np.reshape(xs,(</span><br><span class="line">                BATCH_SIZE,</span><br><span class="line">                forward.IMAGE_SIZE,</span><br><span class="line">                forward.IMAGE_SIZE,</span><br><span class="line">                forward.NUM_CHANNELS</span><br><span class="line">            ))</span><br><span class="line">        <span class="comment"># 喂入训练图像和标签,开始训练</span></span><br><span class="line">        _,loss_value,step=sess.run([train_op,loss,global_step],feed_dict=&#123;x:reshaped_xs,y_:ys&#125;)</span><br><span class="line">        <span class="comment"># 每迭代100次打印loss信息,并保存最新模型</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"After %d training step,loss on training batch is %g."</span> % (step,loss_value))</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试过程<br>1)在测试程序中使用的是训练好的网络,故不使用dropout,而是让所有神经元都参与运算,从而输出识别准确率.<br>2)correct_predicition=tf.equal(tf.argmax(y,1),tf.argmax(y_,1)).<br>tf.equal(x,y)次函数用于判断函数的两个参数x与y是否相等,一般x表示预测值，y表示实际值。<br>3)accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))求平均得到预测准确率。 </p>
<h3 id="Inception-v3模型"><a href="#Inception-v3模型" class="headerlink" title="Inception-v3模型"></a>Inception-v3模型</h3><p>Inception-v3模型是将不同的卷积层通过并联的方式结合在一起。</p>
<img src="/2018/10/29/图像识别与卷积神经网络/inceptionv3.png" title="Inception-v3模型">
</li>
</ol>
<p>下面介绍使用Tensorflow-Slim实现一个卷积层<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用Tensorflow原始API</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(scope_name):</span><br><span class="line">    weights=tf.get_variable(<span class="string">"weights"</span>,...)</span><br><span class="line">    biases=tf.get_variable(<span class="string">"bias"</span>,...)</span><br><span class="line">    conv=tf.nn.conv2d(...)</span><br><span class="line">    relu=tf.nn.relu(tf.nn.bias_add(conv,biases))</span><br><span class="line">    </span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">使用Tensorflow-Slim可以在一行中实现一个卷积层的前向传播算法.有3个必选参数:</span></span><br><span class="line"><span class="string">1. 输入节点矩阵</span></span><br><span class="line"><span class="string">2. 当前卷积层过滤器的深度</span></span><br><span class="line"><span class="string">3. 过滤器的尺寸</span></span><br><span class="line"><span class="string">可选参数:过滤器的移动步长、是否使用全0填充、激活函数的选择以及变量的命名空间</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">net = slim.conv2d(input,<span class="number">32</span>,[<span class="number">3</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure></p>
<h2 id="卷积神经网络的迁移学习"><a href="#卷积神经网络的迁移学习" class="headerlink" title="卷积神经网络的迁移学习"></a>卷积神经网络的迁移学习</h2><p>迁移学习，就是将一个问题上训练好的模型通过简单的调整使其使用于一个新的问题。<br>根据论文DeCAF：A Deep Convolutional Activiation Feature for Generic Visual Recoginition中的结论，可以保留训练好的Inception-v3模型中所有卷积层的参数，只是替换最后这一层全连接层。在最后这一层全连接层之前的网络层称之为瓶颈层。<br>将新的图像通过训练好的卷积神经网络直到瓶颈层的过程可以看成是对图像进行特征提取的过程。在训练好的Inception-v3模型中，因为将瓶颈层的输出再通过一个单层的全连接层神经网络可以很好地区分1000种类别的图像，所以有理由认为瓶颈层输出的节点向量可以被作为任何图像的一个更加精简且表达能力更强的特征向量。于是，在新数据集上，可以直接利用这个训练好的神经网络对图像进行特征提取，然后再将提取得到的特征向量作为输入来训练一个新的单层全连接神经网络处理新的分类问题。</p>
<h2 id="反卷积神经网络"><a href="#反卷积神经网络" class="headerlink" title="反卷积神经网络"></a>反卷积神经网络</h2><p>反卷积是指测量输出和已知输入重构未知输入的过程。在神经网络中，反卷积过程并不具备学习能力，仅用于可视化一个已经训练好的卷积模型，没有学习训练的过程。<br>下图展示了VGG 16反卷积神经网络的结构，展示了一个卷积网络与反卷积网络结合的过程。其反卷积就是将中间的数据，按照前面的卷积、池化等变化过程，完全相反的做一遍，从而得到类似原始输入的数据。<br></p>
<h3 id="反卷积原理"><a href="#反卷积原理" class="headerlink" title="反卷积原理"></a>反卷积原理</h3><ol>
<li>首先将卷积核反转</li>
<li>再将卷积结果作为输入，做补0的扩充操作，即往每一个元素后面补0。这一步是根据步长来的，对每一个元素沿着步长的方向补（步长-1）个0，如步长为1就不用补0.</li>
<li>在扩充后的输入基础上再对整体补0。以原始输入的shape作为输出，按照卷积padding规则计算padding的补0位置及个数，得到的补0位置要上下和左右各自颠倒一下。</li>
<li><p>将补0后的卷积结果作为真正的输入，反转后的卷积核为filter，步长为1的卷积操作。<br>如下图所示，以一个[1,4,4,1]的矩阵为例，进行filter为2x2，步长为2x2的卷积与反卷积操作。在反卷积过程中，首先将2x2矩阵通过步长补0的方式变成4x4，再通过padding反向补0，然后与反转后的filter使用步长为1x1的卷积操作，最终得出了结果。</p>
<img src="/2018/10/29/图像识别与卷积神经网络/conv_unconv.jpg" title="卷积与反卷积操作">
<p> Tensorflow中使用tf.nn.conv2d_transpoze来实现</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d_transpoze</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    value,</span></span></span><br><span class="line"><span class="function"><span class="params">    filter,</span></span></span><br><span class="line"><span class="function"><span class="params">    output_shape,</span></span></span><br><span class="line"><span class="function"><span class="params">    strides,</span></span></span><br><span class="line"><span class="function"><span class="params">    padding=<span class="string">'SAME'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    data_format=<span class="string">'NHWC'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    name=None</span></span></span><br><span class="line"><span class="function"><span class="params">    )</span>:</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<ul>
<li>value:代表通过卷积操作后的张量，一般用NHWC类型。</li>
<li>filter:代表卷积核</li>
<li>output_shape:代表输出的张量形状也是个四维张量.</li>
<li>strides:代表步长</li>
<li>padding:代表原数据生成value时使用的补0，是用来检查输入形状和输出形状是否合规的，</li>
<li><p>return:反卷积后的结果，按照output_shape指定的形状。</p>
<blockquote>
<p>NHWC类型是神经网络中在处理图像方面常用的类型，N-个数、H-高、W-宽、C-通道数。<br>output_shape必须是能够生成value参数的原数据的形状，如果输出形状不对就会报错。</p>
</blockquote>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 模拟数据</span></span><br><span class="line">img = tf.Variable(tf.constant(<span class="number">1.0</span>, shape=[<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>]))</span><br><span class="line">filter = tf.Variable(tf.constant([<span class="number">1.0</span>, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>], shape=[<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line"><span class="comment"># 分别进行VALID和SAME操作</span></span><br><span class="line">conv = tf.nn.conv2d(img, filter, strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'VALID'</span>)</span><br><span class="line">cons = tf.nn.conv2d(img, filter, strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">print(conv.shape)</span><br><span class="line">print(cons.shape)</span><br><span class="line"><span class="comment"># 再进行反卷积</span></span><br><span class="line">contv = tf.nn.conv2d_transpose(</span><br><span class="line">    conv, filter, [<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'VALID'</span>)</span><br><span class="line">conts = tf.nn.conv2d_transpose(</span><br><span class="line">    cons, filter, [<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(<span class="string">"conv:"</span>, sess.run([conv]))</span><br><span class="line">    print(<span class="string">"cons:"</span>, sess.run([cons]))</span><br><span class="line">    print(<span class="string">"contv:"</span>, sess.run([contv]))</span><br><span class="line">    print(<span class="string">"conts:"</span>, sess.run([conts]))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="反池化原理"><a href="#反池化原理" class="headerlink" title="反池化原理"></a>反池化原理</h3><p>池化过程是只保留主要信息，舍去部分信息，如果想从池化后的这些主要信息恢复出全部信息，则存在着信息缺失，这时只能通过补位来实现最大程度的信息完整。</p>
<ul>
<li>平均池化的反池化比较简单。首先还原成原来的大小，然后将池化结果中的每个值都填入其对应原始数据区域中相应位置即可。<img src="/2018/10/29/图像识别与卷积神经网络/avg_pooling.jpg" title="反平均池化"></li>
<li>最大池化反池化。要求在池化过程中记录最大激活值的坐标位置，然后在反池化时，只把池化过程中最大激活值所在位置坐标的值激活，其他位置为0.<img src="/2018/10/29/图像识别与卷积神经网络/max_pooling.jpg" title="反最大池化"></li>
</ul>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="https://geolibra.github.io">hgis</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="https://geolibra.github.io/2018/10/29/图像识别与卷积神经网络/">https://geolibra.github.io/2018/10/29/图像识别与卷积神经网络/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span>
      
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/Tensorflow/">Tensorflow</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2018/10/29/Dymaxion-map/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Dymaxion map</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2018/10/20/nginx-实战/">
        <span class="next-text nav-default">nginx 实战</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:674530915@qq.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/GeoLibra" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>


<div class="copyright">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
  <span class="post-meta-divider">|</span>
  <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人</span>


  <span class="copyright-year">
    
    &copy; 
    
    2018

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">hgis</span>
    <span id="busuanzi_container_site_uv">
    </span>
</span>
</div>



      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  

  



    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.1"></script>

  </body>
</html>
