<!DOCTYPE html>
<html lang="">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="搭建神经网络的八股"/>




  <meta name="keywords" content="Tensorflow, 深度学习, 磊哥的小书桌" />










  <link rel="alternate" href="/default" title="磊哥的小书桌">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.1" />



<link rel="canonical" href="https://geolibra.github.io/2018/10/11/搭建神经网络的八股/"/>



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css" />



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.1" />



  <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?97659041a2db55d3eb7266f53be7c071";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>





  <script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
  <script id="leancloud">
    AV.init({
      appId: "ro3TOe5F5DDemxHnSoYVCHli-gzGzoHsz",
      appKey: "IHyD5EfrggPl57FnwtBEeH0W"
    });
  </script>




<script>
  window.config = {"title":"磊哥的小书桌","subtitle":null,"description":null,"author":"hgis","language":null,"timezone":null,"url":"https://geolibra.github.io","root":"/","permalink":":year/:month/:day/:title/","permalink_defaults":null,"source_dir":"source","public_dir":"public","tag_dir":"tags","archive_dir":"archives","category_dir":"categories","code_dir":"downloads/code","i18n_dir":":lang","skip_render":null,"new_post_name":":title.md","default_layout":"post","titlecase":false,"external_link":true,"filename_case":0,"render_drafts":false,"post_asset_folder":true,"relative_link":false,"future":true,"highlight":{"enable":true,"auto_detect":false,"line_number":true,"tab_replace":null,"first_line_number":"always1"},"default_category":"uncategorized","category_map":null,"tag_map":null,"date_format":"YYYY-MM-DD","time_format":"HH:mm:ss","per_page":10,"pagination_dir":"page","theme":"even","deploy":{"type":"git","repository":"git@github.com:GeoLibra/GeoLibra.github.io.git","branch":"master"},"ignore":[],"keywords":null,"email":"674530915@qq.com","index_generator":{"per_page":10,"order_by":"-date","path":""},"tag_cloud":{"textFont":"Trebuchet MS, Helvetica","textColour":"\\#eea849","textHeight":25,"outlineColour":"\\#E2E1D1"},"category_generator":{"per_page":10},"archive_generator":{"per_page":10,"yearly":true,"monthly":true,"daily":false},"tag_generator":{"per_page":10},"marked":{"gfm":true,"pedantic":false,"sanitize":false,"tables":true,"breaks":true,"smartLists":true,"smartypants":true,"modifyAnchors":"","autolink":true},"server":{"port":4000,"log":false,"compress":false,"header":true},"since":2018,"favicon":"/favicon.ico","rss":"default","menu":{"Home":"/","Archives":"/archives/","Tags":"/tags","Categories":"/categories","About":"/about"},"color":"default","mode":"default","toc":true,"fancybox":true,"pjax":true,"copyright":{"enable":true,"license":"<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\" target=\"_blank\">知识共享署名-非商业性使用 4.0 国际许可协议</a>"},"reward":{"enable":false,"qrCode":{"wechat":null,"alipay":null}},"social":{"email":"674530915@qq.com","stack-overflow":null,"twitter":null,"facebook":null,"linkedin":null,"google":null,"github":"https://github.com/GeoLibra","weibo":null,"zhihu":null,"douban":null,"pocket":null,"tumblr":null,"instagram":null},"leancloud":{"app_id":"ro3TOe5F5DDemxHnSoYVCHli-gzGzoHsz","app_key":"IHyD5EfrggPl57FnwtBEeH0W"},"baidu_analytics":"97659041a2db55d3eb7266f53be7c071","baidu_verification":null,"google_analytics":null,"google_verification":null,"disqus_shortname":null,"changyan":{"appid":null,"appkey":null},"livere_datauid":null,"counter":true,"version":"2.10.1"};
</script>

    <title> 搭建神经网络的八股 - 磊哥的小书桌 </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">磊哥的小书桌</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            分类
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">磊哥的小书桌</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          搭建神经网络的八股
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-10-11
        </span>
        
          <span class="post-category">
            
              <a href="/categories/深度学习/">深度学习</a>
            
          </span>
        
        
        <span class="post-visits"
             data-url="/2018/10/11/搭建神经网络的八股/"
             data-title="搭建神经网络的八股">
          阅读次数 0
        </span>
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#前向传播"><span class="toc-text">前向传播</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#反向传播"><span class="toc-text">反向传播</span></a></li></ol>
    </div>
  </div>



    <div class="post-content">
      
        <h2 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h2><p>由输入到输出,搭建完整的网络结构<br>描述前向传播的过程需要定义三个函数:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(x,regularizer)</span>:</span></span><br><span class="line">    w=</span><br><span class="line">    b=</span><br><span class="line">    y=</span><br><span class="line">    retutn y</span><br></pre></td></tr></table></figure></p>
<p>第一个函数forward完成网络结构设计，从输入到输出搭建完整的网络结构，实现前向传播过程。该函数中，参数x为输入，regularizer为正则化权重，返回值为预测或分类结果y。<br><a id="more"></a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weight</span><span class="params">(shape,regularizer)</span>:</span></span><br><span class="line">    w=tf.Variable()</span><br><span class="line">    tf.add_to_collection(<span class="string">'losses'</span>,tf.contrib.layers.l2_regularizer(regularizer)(w))</span><br><span class="line">    <span class="keyword">return</span> w</span><br></pre></td></tr></table></figure></p>
<p>第二个函数get_weight对参数w设定。该函数中，参数shape表示参数w的形状，regularizer表示正则化权重，返回值为参数w。其中，tf.Variable给w赋初值，tf.add_to_collection表示将参数w正则化损失加到总损失losses中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_bias</span><span class="params">(shape)</span>:</span></span><br><span class="line">    b=tf.Variable()</span><br><span class="line">    <span class="keyword">return</span> b</span><br></pre></td></tr></table></figure></p>
<p>第三个函数get_bias对参数b进行设定。该函数中，参数shape表示参数b的形状，返回值为参数b。其中，tf.Variable表示给b赋初值。</p>
<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p>训练网络，优化网络参数，提高模型准确性。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">()</span>:</span></span><br><span class="line">    x=tf.placeholder()</span><br><span class="line">    y_=tf.placeholder()</span><br><span class="line">    y=forward.froward(x,REGULARIZER)</span><br><span class="line">    global_step=tf.Variable(<span class="number">0</span>,trainable=<span class="keyword">False</span>)</span><br><span class="line">    loss=</span><br></pre></td></tr></table></figure></p>
<p>函数backward中，placeholder实现对数据集x和标准答案y_占位，forward.forward实现前向传播的网络结构，参数global_step表示训练轮数，设置为不可训练参数。在训练网络模型时，常将正则化、指数衰减学习率和滑动平均这三个方法作为模型优化方法。<br>在Tensorflow中正则化表示为：</p>
<p>首先，计算预测结果与标准答案的损失值。</p>
<ul>
<li>MSE:y与y_的差距(loss_mse)=tf.reduce_mean(tf.square(y-y_))</li>
<li>交叉熵:ce=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=tf.argmax(y_,1));y与y_的差距(cem)=tf.reduce_mean(ce)</li>
<li>自定义:y与y_的差距<br>其次，总损失值为预测结果与标准答案的损失值加上正则化项。<br>loss=y与y_的差距+tf.add_n(tf.get_collection(‘losses’))</li>
</ul>
<p>在Tensorflow中，指数衰减学习率表示为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">learning_rate=tf.train.exponential_decay(</span><br><span class="line">    LEARNINR_RATE_BASE,</span><br><span class="line">    global_step,</span><br><span class="line">    数据集总样本数/BATCH_SIZE,</span><br><span class="line">    LEARNING_RATE_DECAY,</span><br><span class="line">    staircase=<span class="keyword">True</span></span><br><span class="line">)</span><br><span class="line">train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)</span><br></pre></td></tr></table></figure></p>
<p>在Tensorflow中，滑动平均表示为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ema=tf.train.ExponentialMovineAverage(MOVING_AVERAGE_DECAY,globa_step)</span><br><span class="line">ema_op=ema.apply(tf.trianable_variables())</span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies([train_step,ema_op]):</span><br><span class="line">    train_op=tf.no_op(name=<span class="string">'train'</span>)</span><br></pre></td></tr></table></figure></p>
<p>其中，滑动平均和指数衰减学习率中global_step是同一个参数。</p>
<p>用with结构化所有参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op=tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line">        sess.run(train_step,feed_dict=&#123;x:,y_:&#125;)</span><br><span class="line">        <span class="keyword">if</span> i % 轮数==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span></span><br></pre></td></tr></table></figure>
<p>一个完整的神经网络实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 定义训练数据batch的大小</span></span><br><span class="line">batch_size = <span class="number">8</span></span><br><span class="line">seed = <span class="number">1</span></span><br><span class="line"><span class="comment"># 定义神经网络的参数</span></span><br><span class="line">w1 = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">3</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line">w2 = tf.Variable(tf.random_normal([<span class="number">3</span>, <span class="number">1</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">在shape的一个维度上使用None可以方便的使用不同的batch大小.在训练时需要把数据分成比较小的batch,</span></span><br><span class="line"><span class="string">但是测试时可以一次性使用全部数据,当数据集比较小时这样比较方便测试,但数据集比较大时,将大量数据放</span></span><br><span class="line"><span class="string">入一个batch可能会导致内存溢出</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># 定义神经网络的输入、输出</span></span><br><span class="line">x = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, <span class="number">2</span>), name=<span class="string">'x-input'</span>)</span><br><span class="line">y_ = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, <span class="number">1</span>), name=<span class="string">'y-input'</span>)  <span class="comment"># 标准答案</span></span><br><span class="line"><span class="comment"># 定义神经网络前向传播过程</span></span><br><span class="line">a = tf.matmul(x, w1)</span><br><span class="line">y = tf.matmul(a, w2)</span><br><span class="line"><span class="comment"># 定义损失函数和反向传播的算法</span></span><br><span class="line">y = tf.sigmoid(y)</span><br><span class="line">cross_entropy = -tf.reduce_mean(</span><br><span class="line">    y_ * tf.log(tf.clip_by_value(y, <span class="number">1e-10</span>, <span class="number">1.0</span>)) +</span><br><span class="line">    (<span class="number">1</span> - y) * tf.log(tf.clip_by_value(<span class="number">1</span> - y, <span class="number">1e-10</span>, <span class="number">1.0</span>)))</span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)</span><br><span class="line"><span class="comment"># 通过随机数生成一个模拟的数据集</span></span><br><span class="line">rdm = np.random.RandomState(seed=<span class="number">1</span>)</span><br><span class="line">dataset_size = <span class="number">128</span></span><br><span class="line">X = rdm.rand(dataset_size, <span class="number">2</span>)</span><br><span class="line">Y = [[int(x1 + x2 &lt; <span class="number">1</span>)] <span class="keyword">for</span> (x1, x2) <span class="keyword">in</span> X]</span><br><span class="line"><span class="comment"># 创建一个回话来运行Tensorflow程序</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    <span class="comment"># 初始化变量</span></span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    print(<span class="string">"训练之前,神经网络的参数值"</span>)</span><br><span class="line">    print(sess.run(w1))</span><br><span class="line">    print(sess.run(w2))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设定训练的轮数</span></span><br><span class="line">    STEPS = <span class="number">5000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line">        <span class="comment"># 每次选取batch_size个样本进行训练</span></span><br><span class="line">        start = (i * batch_size) % dataset_size</span><br><span class="line">        end = min(start + batch_size, dataset_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 通过选取的样本训练神经网络并更新参数</span></span><br><span class="line">        sess.run(train_step, feed_dict=&#123;x: X[start:end], y_: Y[start:end]&#125;)</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 每隔一段时间计算在所有数据上的交叉熵并输出</span></span><br><span class="line">            total_cross_entropy = sess.run(</span><br><span class="line">                cross_entropy, feed_dict=&#123;</span><br><span class="line">                    x: X,</span><br><span class="line">                    y_: Y</span><br><span class="line">                &#125;)</span><br><span class="line">            print(<span class="string">"After %d training steps,cross entroy on all data is %g"</span> %</span><br><span class="line">                  (i, total_cross_entropy))</span><br><span class="line">    print(<span class="string">"训练之后的神经网络参数"</span>)</span><br><span class="line">    print(sess.run(w1))</span><br><span class="line">    print(sess.run(w2))</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">1. 定义神经网络的结构和前向传播的输出结果</span></span><br><span class="line"><span class="string">2. 定义损失函数以及选择反向传播优化算法</span></span><br><span class="line"><span class="string">3. 生成回话并在训练数据上反复运行反向传播优化算法</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure></p>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="https://geolibra.github.io">hgis</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="https://geolibra.github.io/2018/10/11/搭建神经网络的八股/">https://geolibra.github.io/2018/10/11/搭建神经网络的八股/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span>
      
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/Tensorflow/">Tensorflow</a>
            
              <a href="/tags/深度学习/">深度学习</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2018/10/14/判断点与多边形的关系/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">判断点与多边形的关系</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2018/09/28/Python3安装Scrapy/">
        <span class="next-text nav-default">Python3安装Scrapy</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:674530915@qq.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/GeoLibra" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>


<div class="copyright">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
  <span class="post-meta-divider">|</span>
  <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人</span>


  <span class="copyright-year">
    
    &copy; 
    
    2018

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">hgis</span>
    <span id="busuanzi_container_site_uv">
    </span>
</span>
</div>



      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  

  



    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.1"></script>

  </body>
</html>
